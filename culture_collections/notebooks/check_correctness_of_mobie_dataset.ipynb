{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48e8bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152020/4237793295.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Any\n",
    "import subprocess\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c6bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table\n",
    "with open('/home/hellgoth/Documents/work/projects/culture-collections_project/culture-collections/data/new_names/dataset.json', 'r') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d6db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1636\n",
      "True\n",
      "1636\n"
     ]
    }
   ],
   "source": [
    "# general checks\n",
    "print(len(dataset[\"views\"]))\n",
    "print(\"default\" in dataset[\"views\"])\n",
    "print(len(set(dataset[\"views\"].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d48888d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load abbreviations & add func to check for valid names\n",
    "with open(\"abbreviations.csv\", \"r\") as f:\n",
    "    abbreviations = pd.read_csv(f, sep=\"\\t\", dtype=str)\n",
    "\n",
    "ids = abbreviations[\"ids\"].dropna().tolist()\n",
    "fixes = abbreviations[\"fixes\"].dropna().tolist()\n",
    "channels = abbreviations[\"channels\"].dropna().tolist()\n",
    "dates = abbreviations[\"dates\"].dropna().tolist()\n",
    "researchers = abbreviations[\"researchers\"].dropna().tolist()\n",
    "extra = abbreviations[\"extra\"].dropna().tolist()\n",
    "\n",
    "def is_valid_name(name: str) -> bool:\n",
    "    split = name.split(\"_\")\n",
    "    if len(split) < 5:\n",
    "        print(f\"{name} is too short, must be at least 5 parts\")\n",
    "        return False\n",
    "    if split[0] not in ids:\n",
    "        print(f\"{name} has invalid id {split[0]}\")\n",
    "        return False\n",
    "    if split[1] not in fixes:\n",
    "        print(f\"{name} has invalid fix {split[1]}\")\n",
    "        return False\n",
    "    cs = split[2].split(\"-\")\n",
    "    for c in cs:\n",
    "        if c not in channels:\n",
    "            print(f\"{name} has invalid channel {c}\")\n",
    "            return False\n",
    "    if split[3] not in dates:\n",
    "        print(f\"{name} has invalid date {split[3]}\")\n",
    "        return False\n",
    "    if split[4] not in researchers:\n",
    "        print(f\"{name} has invalid researcher {split[4]}\")\n",
    "        return False\n",
    "    if len(split) > 5 and split[5] not in extra:\n",
    "        print(f\"{name} has invalid extra {split[5]}\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1b248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = {\n",
    "    \"nhs\": \"white\",\n",
    "    \"bod\": \"white\",\n",
    "    \"tub\": \"magenta\",\n",
    "    \"cetn\": \"yellow\",\n",
    "    \"dna\": \"blue\",\n",
    "    \"npc\": \"green\",\n",
    "}\n",
    "ALT_COLORS = [\"orange\", \"red\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e13545e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = subprocess.check_output([\"mc\", \"ls\", f\"culcol_s3_ro/culture-collections/data/single_volumes/images/ome-zarr/\"], text=True)\n",
    "all_files = all_files.replace(all_files[:34], \"\")\n",
    "all_files = all_files.split(\"/\\n\")[:-1]\n",
    "print(len(all_files))\n",
    "len(all_files) == len(set(all_files))  # check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed10a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "\n",
    "\n",
    "client = Minio(\n",
    "    \"s3.embl.de\",\n",
    "    access_key=\"CulColROPubKey\",\n",
    "    secret_key=\"ReadCultureCollections092023\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1233ce79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contrast limits for rcc999rcc2538_pfa_dna-tub-nhs_20230728_csd_04 are not set: [0, 256]\n",
      "Contrast limits for rcc10709_pfa_dna-tub-nhs_20230829_csd_07 are not set: [0, 256]\n"
     ]
    }
   ],
   "source": [
    "# iterate through views\n",
    "for view_name, view in dataset[\"views\"].items():\n",
    "    # skip default view\n",
    "    if view_name == \"default\":\n",
    "        continue\n",
    "\n",
    "    # check if view name is valid\n",
    "    if not is_valid_name(view_name):\n",
    "        print(f\"Invalid name found: {view_name}\")\n",
    "        continue\n",
    "\n",
    "    # iterate through sourceDisplays\n",
    "    color_counter = 0\n",
    "    for i, source_display in enumerate(view[\"sourceDisplays\"]):\n",
    "        # check contrast limits\n",
    "        cl = source_display[\"imageDisplay\"][\"contrastLimits\"]\n",
    "        if cl == [0, 2**8] or cl == [0, 2**16]:\n",
    "            print(f\"Contrast limits for {view_name} are not set: {cl}\")\n",
    "\n",
    "        # check channel order\n",
    "        channels_from_name = view_name.split(\"_\")[2].split(\"-\")\n",
    "        channel_name_from_dataset = source_display[\"imageDisplay\"][\"name\"]\n",
    "        if i != channels_from_name.index(channel_name_from_dataset):\n",
    "            print(\n",
    "                f\"Channel order mismatch in {view_name}: {channel_name_from_dataset} not at index {i}\"\n",
    "            )\n",
    "\n",
    "        # check channel color\n",
    "        if channel_name_from_dataset == \"na\":\n",
    "            exp_color = \"black\"\n",
    "        elif channel_name_from_dataset == \"bod\" and \"nhs\" in channels_from_name:\n",
    "            exp_color = \"orange\"\n",
    "        elif channel_name_from_dataset not in COLORS:\n",
    "            exp_color = ALT_COLORS[color_counter]\n",
    "            color_counter += 1\n",
    "        else:\n",
    "            exp_color = COLORS[channel_name_from_dataset]\n",
    "        if source_display[\"imageDisplay\"][\"color\"] != exp_color:\n",
    "            print(\n",
    "                f\"Color mismatch in {view_name} for channel {channel_name_from_dataset}: expected {exp_color}, got {source_display['imageDisplay']['color']}\"\n",
    "            )\n",
    "\n",
    "        # check source name\n",
    "        source_names = source_display[\"imageDisplay\"][\"sources\"]\n",
    "        if not len(source_names) == 1:\n",
    "            print(f\"Should have only one source: {view_name}\")\n",
    "            continue\n",
    "        source_name = source_names[0]\n",
    "        if not is_valid_name(\n",
    "            \"_\".join(source_name.split(\"_\")[:-1])\n",
    "            if source_name.split(\"_\")[-1].startswith(\"ch\")\n",
    "            else source_name\n",
    "        ):\n",
    "            print(f\"Invalid source name found: {source_name}\")\n",
    "\n",
    "        # jump to source\n",
    "        source = dataset[\"sources\"][source_name]\n",
    "        # check channel idx\n",
    "        if source_name.split(\"_\")[-1].startswith(\"ch\"):\n",
    "            exp_channel_idx = int(source_name.split(\"_\")[-1][2:])\n",
    "            if not (\n",
    "                source[\"image\"][\"imageData\"][\"ome.zarr\"][\"channel\"]\n",
    "                == source[\"image\"][\"imageData\"][\"ome.zarr.s3\"][\"channel\"]\n",
    "                == exp_channel_idx\n",
    "            ):\n",
    "                print(\n",
    "                    f\"Channel index mismatch in {view_name} for source {source_name}: expected {exp_channel_idx}, got {source['image']['ome.zarr']['channel']}\"\n",
    "                )\n",
    "        else:  # Hiral's case\n",
    "            if \"channel\" in source[\"image\"][\"imageData\"][\"ome.zarr\"] or \"channel\" in source[\"image\"][\"imageData\"][\"ome.zarr.s3\"]:\n",
    "                print(\n",
    "                    f\"Channel index found in {view_name} for source {source_name} but not expected\"\n",
    "                )\n",
    "        \n",
    "        # check for valid file name\n",
    "        local_file_name = source[\"image\"][\"imageData\"][\"ome.zarr\"][\"relativePath\"].split(\"/\")[2]\n",
    "        remote_file_name = source[\"image\"][\"imageData\"][\"ome.zarr.s3\"][\"s3Address\"].split(\"/\")[8]\n",
    "        if local_file_name != remote_file_name:\n",
    "            print(\n",
    "                f\"File name mismatch in {view_name} for source {source_name}: {local_file_name} != {remote_file_name}\"\n",
    "            )\n",
    "        # if not is_valid_name(local_file_name.replace(\".ome.zarr\", \"\")):\n",
    "        #     print(f\"Invalid source name found: {source_name}\")\n",
    "\n",
    "        # check for file existence\n",
    "        if remote_file_name not in all_files:\n",
    "            print(f\"File {local_file_name} not found in S3 bucket for {view_name}\")\n",
    "\n",
    "        # check that vol exists\n",
    "        series = source[\"image\"][\"imageData\"][\"ome.zarr.s3\"][\"s3Address\"].split(\"/\")[9]\n",
    "        resolution = 0\n",
    "        timepoint = 0\n",
    "        channel = 0\n",
    "        if source_name.split(\"_\")[-1].startswith(\"ch\"):\n",
    "            channel = int(source_name.split(\"_\")[-1][2:])\n",
    "        objs = [\n",
    "            obj.object_name\n",
    "            for obj in client.list_objects(\n",
    "                \"culture-collections\",\n",
    "                prefix=f\"data/single_volumes/images/ome-zarr/{remote_file_name}/{series}/{resolution}/{timepoint}/{channel}/\",\n",
    "            )\n",
    "        ]\n",
    "        if len(objs) == 0:\n",
    "            print(\n",
    "                f\"Volume {remote_file_name}/{series}/{resolution}/{timepoint}/{channel} not found in S3 bucket for {view_name}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d93064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "culture-collections",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
